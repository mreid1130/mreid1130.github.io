<!DOCTYPE html>
<html lang="en">

<head>
  <title>Mark Reid - Blog</title>
  <link rel="stylesheet" type="text/css" href="../css/foundation.min.css">
  <link rel="stylesheet" type="text/css" href="../css/prism.css">
  <link rel="stylesheet" type="text/css" href="../css/style.css">
  <script type="text/javascript" src="../js/jquery.js"></script>
  <script type="text/javascript" src="../js/foundation.min.js"></script>
  <script type="text/javascript" src="../js/prism.js"></script>
  <script type="text/javascript" src="../js/controller.js"></script>
</head>

<body>
  <div class='container'>
    <div class="row">
      <div class="nav top-bar large-12 small-centered columns">
        <div class="pull-left name">MARK REID</div>
        <div id="logo">
          <a href="../index.html"><img src="http://www.clipartkid.com/images/682/yoyruho-png-8OSXwy-clipart.png"></a>
        </div>
        <ul class="pull-right right">
          <li><a href="../index.html">ABOUT</a></li>
          <li><a href="../portfolio.html">PORTFOLIO</a></li>
          <li><a class="active" href="../blog.html">BLOG</a></li>
        </ul>
      </div>
    </div>
    <div class="row">
      <div class="small-12 large-8 columns">
        <div class="row">
          <div class="small-12 columns">
            <div class="blog-header">
              <div class="top">
                <p class="date pull-right">Oct. 2, 2016</p>
              </div>
              <h1 class="blog-title">Web Scraping with Node</h1>
              <p class="sub-title">This tutorial will cover scraping both a static and dynamic content site utilizing Node, Cheerio, and PhantomJS.</p>
              <div class="bottom">
                <p>Mark Reid</p>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="small-12 columns">
            <div class="blog-body">
              <p>Building web scrapers has been something that's been asked of me quite often at work, and I'm hoping this tutorial will help teach a few simple ways to practice grabbing data from your favorite sites.</p>
              <p>In this tutorial, I'll be using Node packages request and cheerio to scrape static pages and PhantomJS and cheerio to scrape dynamic pages. I'll also be using the async library to help manage asyncronous requests.</p>
              <p>Cheerio is a basic server-side implementation of jQuery. That means that given a DOM in the form of a string, cheerio can parse that string and we can perform jQuery like operations to collect data from the DOM.</p>
              <p>PhantomJS is a library which will allow us to make a request to a given URL and execute JavaScript on the page. This can include simulating user actions such as scrolling, clicking, key-pressing, etc. This is a powerful set of tools to have when doing automated browser testing or in our case, scraping data from a page. With the rising popularity of SPAs, web scraping has become more difficult for sites built with certain frameworks and those that execute JavaScript to inject content dynamically.</p>
              <p>First, we'll start off scraping a static page and grabbing the title element from the DOM:</p>
              <pre class="language-javascript line-numbers">
                <code class="language-javascript">
                  var cheerio = require('cheerio');
                  var request = require('request');
                  var async = require('async');

                  async.waterfall([
                    (callback) => {
                      request('https://google.com', callback);
                    }, (res, body, callback) => {
                      var $ = cheerio.load(body);

                      var title = $('title');

                      callback(null, title);
                    }
                  ], (err, title) => {
                    if (err) {
                      console.log(err.stack);
                    }
                    console.log('Page title is:', title);
                  });
                </code>
              </pre>
              <p>If you run the code in your local node environment with the installed packages, you should see the following logline: "Page title is: Google"</p>
            </div>
          </div>
        </div>
      </div>
      <div class="small-12 large-4 columns">
        <div class="blog-list-header">
          <h2>Blog Posts</h2>
        </div>
        <div class="blog-list-sidebar">
          <a href="../blog/web-scraping-node.html">
            <div class="active blog-list-item">
              <div class="blog-list-item-title">Web Scraping with Node</div>
            </div>
          </a>
          <div class="blog-list-item">
            <div class="blog-list-item-title">Continuous Integration with Node + CircleCI</div>
          </div>
          <div class="blog-list-item">
            <div class="blog-list-item-title">Dockerizing a Node app</div>
          </div>
          <div class="blog-list-item">
            <div class="blog-list-item-title">Amazon SQS Tutorial</div>
          </div>
        </div>
      </div>
    </div>
  </div>
</body>
